{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This tutoral was created to attempt to give a someone with little to no experiance with data\n",
    "science an intro into data processing and machine learning.\n",
    "In this tutorial we will attempt to learn about machine learning by doing some predictions. Well cover a number of steps that are required to create a model:\n",
    "    - import the data from a cvs to a dataframe\n",
    "    - preprocess the data\n",
    "        - remove null values\n",
    "        - create x and y set for features and target comunm\n",
    "        - apply scaling\n",
    "        - split the data into train test sets\n",
    "    - create a model\n",
    "        - fit the data to the model\n",
    "        - get a prediction from the model\n",
    "    - confusion matrix to view predictions\n",
    "        \n",
    "To attempt to do this we will use a dataset that contains information about weather in seattle \n",
    "more specfically wheather or not it rained covering everyday from 1948 to 2017. \n",
    "The data in the data set is date, percipation, TMAX(Temperature max) TMIN(Temperature min) and \n",
    "wheather or not it rained.\n",
    "\n",
    "  \n",
    "The data set can be downloaded from kaggle at the following link:<br>-  https://www.kaggle.com/rtatman/did-it-rain-in-seattle-19482017\n",
    "\n",
    "Other useful information/links<br>\n",
    "\n",
    "Pandas:<br>-  https://pandas.pydata.org/<br>\n",
    "\n",
    "Scikit learn:<br>-  https://scikit-learn.org/stable/<br>\n",
    "\n",
    "Train test split:<br>-  https://scikitlearn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html<br>\n",
    "\n",
    "Logistic Regression:<br>-  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html<br>\n",
    "\n",
    "Scikit Learn min max_scale:<br>https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.minmax_scale.html\n",
    "\n",
    "Confusion Matrix:<br>-  https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first thing we will do is import some libraries we will need that are available in python.\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data\n",
    "The data is located in a csv file which is in the same folder as this notebook. We will first get the csv file and then read it into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = os.path.join(\"seattleWeather_1948-2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place the data from csv into a data frame.\n",
    "df = pd.read_csv(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>RAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>0.47</td>\n",
       "      <td>51</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1948-01-02</td>\n",
       "      <td>0.59</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1948-01-03</td>\n",
       "      <td>0.42</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1948-01-04</td>\n",
       "      <td>0.31</td>\n",
       "      <td>45</td>\n",
       "      <td>34</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1948-01-05</td>\n",
       "      <td>0.17</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  PRCP  TMAX  TMIN  RAIN\n",
       "0  1948-01-01  0.47    51    42  True\n",
       "1  1948-01-02  0.59    45    36  True\n",
       "2  1948-01-03  0.42    45    35  True\n",
       "3  1948-01-04  0.31    45    34  True\n",
       "4  1948-01-05  0.17    45    32  True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the data was imported\n",
    "# This command shows the first 5 entries of a data frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>RAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25546</th>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25547</th>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25548</th>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25549</th>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25550</th>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE  PRCP  TMAX  TMIN   RAIN\n",
       "25546  2017-12-10   0.0    49    34  False\n",
       "25547  2017-12-11   0.0    49    29  False\n",
       "25548  2017-12-12   0.0    46    32  False\n",
       "25549  2017-12-13   0.0    48    34  False\n",
       "25550  2017-12-14   0.0    50    36  False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This command will show the last 5 entries of a data frame\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25551, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the data (number of rows and columns, 25551 rows with 5 Columns) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "In the preprocessing stage we will check for null values and deal with them if we find any. We will create a feature set (columns used for the predictions) and a target set (column we are trying to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any rows contain null\n",
    "df.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three rows that contain null values, although this is a low number of null values for dataset with 25551 rows we have to deal with them to ensure that it does not affect the results there are a number of ways we can deal with the null values we can just remove them, we can set them to an average value based on the column containing it or we can set them to a median value which is a value right in the middle of all the values in the colums. Generally 3 out of 25000 probably wont cause a problem but for practice and good standards we will deal with the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below command will drop any row which contains a  null value in any column.  \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25548, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data frame now contains 3 less rows\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction columns and target column\n",
    "In the next step we will split the dataset into an x and y set, x will be the columns we want to use \n",
    "for the predictions and y will be the column we want to  predict, i.e. x will be PCRP, TMAX, TMIN and y will be the RAIN column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.47</td>\n",
       "      <td>51</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.59</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.42</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.31</td>\n",
       "      <td>45</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.17</td>\n",
       "      <td>45</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRCP  TMAX  TMIN\n",
       "0  0.47    51    42\n",
       "1  0.59    45    36\n",
       "2  0.42    45    35\n",
       "3  0.31    45    34\n",
       "4  0.17    45    32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y=y.astype('bool') tells the system that the value is a boolean\n",
    "\n",
    "features = ['PRCP', 'TMAX', 'TMIN']\n",
    "x = df[features]\n",
    "y = df['RAIN']\n",
    "y=y.astype('bool')\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1    True\n",
       "2    True\n",
       "3    True\n",
       "4    True\n",
       "Name: RAIN, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "We will apply scaling to the dataset, the purpose of scaling is to scale the features to a given range i.e. (1, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default minmax_scale uses the values 1, 0 so we do not need to provide the range\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "x = minmax_scale(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test, Split\n",
    "we will split the dat up into a training set ans a test set. The data will be split 70/30, 70 to training and 30 to testing. We will do this by using the train_test_split function from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to train and test the data we will use the train_test_split function from sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to test and train sets. This data is spilt 70-30 this can be changed by changing the \n",
    "# test_size in the parameters\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17883, 3)\n",
      "(7665, 3)\n",
      "(17883,)\n",
      "(7665,)\n"
     ]
    }
   ],
   "source": [
    "# Check the sets\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "In this tutorial we will use a Logistic Regression model from the sklearn module \n",
    "to perform the predictions. Logistic regressionis is a predictive analysis. Logistic regression is used to to describe data and explain th relationshp between one dependent binary variable and ine or more nominal, ordinal, interval, or ratio-level independent variables. With python and scikit learn it is very easy to swap between other models if you wish for further\n",
    "practice. Decision trees, random forrest, SVM, or Gradient boosting can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the data to the model\n",
    "\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8612648884415367"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how well our model is performing\n",
    "lr.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a prediction\n",
    "prediction = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855968688845\n"
     ]
    }
   ],
   "source": [
    "# Get an accuracy score to test how well the model will perform\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix \n",
    "In order to show the predictions of the model we will use a confusion matrix. The confusion matrix for this \n",
    "model will be a 2*2 array as this is a binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4099,  294],\n",
       "       [ 810, 2462]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test, prediction)\n",
    "cnf_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to read this is the diagonal from top left to bottom right are correct predictions and from top right to bottom left are incorrect predictions.\n",
    "\n",
    "In case anyone is confused :-) as to where the values in the matrix array are comming from:\n",
    "4099 + 294 + 810 + 2462 = 7665 = the test set size. The array above shows 4099 accurate prediction for No Rain and 294 incoerrect predictions and 2462 correct predictions for Rain and 810 incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Rain accurate predictions :  4099\n",
      "Correct rain predictions :  2462\n"
     ]
    }
   ],
   "source": [
    "print('No Rain accurate predictions : ', cnf_matrix[0,0])\n",
    "print('Correct rain predictions : ', cnf_matrix[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 85.60%\n"
     ]
    }
   ],
   "source": [
    "result = metrics.accuracy_score(y_test, prediction) *100\n",
    "print(\"Accuracy = {0:.2f}%\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this model is 85.60% which is good anything over 80% is considered to be good accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION:\n",
    "    - On this jupyter notebook we learned how to:\n",
    "    - read in data from a csv file into a python dataframe\n",
    "    - split the data into x (the features) and y (the target column)\n",
    "    - process the data i.e. remove the null values and apply scaling\n",
    "    - split the data to create a training and test set \n",
    "    - create a model and fit the data to it, here we used Logistic Regression\n",
    "    - get predictions based on the test set\n",
    "    - create a confusion matrix to interperate the results and make sense of them\n",
    "    - use metrics i.e. accuracy to show how the model is performing\n",
    "\n",
    " With the way I created this tutorial anyone should be able to swap the model for any\n",
    " other classification model without to many issues. All the information you would need is available from scikit learn here:-  https://scikit-learn.org/stable/index.html "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
